# backend/whisper_service.py
from openai import OpenAI
from config import Config
import os
import tempfile
import subprocess
import math

client = OpenAI(api_key=Config.OPENAI_API_KEY)

MAX_SIZE_BYTES = 25 * 1024 * 1024  # 25MB


def get_audio_duration(file_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ ê¸¸ì´ í™•ì¸ (ì´ˆ)"""
    try:
        result = subprocess.run([
            'ffprobe', '-v', 'error', '-show_entries', 
            'format=duration', '-of', 
            'default=noprint_wrappers=1:nokey=1', file_path
        ], capture_output=True, text=True)
        return float(result.stdout.strip())
    except:
        return 0


def compress_audio(input_path, output_path, target_size_mb=24):
    """ì˜¤ë””ì˜¤ ì••ì¶• (ffmpeg ì‚¬ìš©)"""
    try:
        duration = get_audio_duration(input_path)
        if duration <= 0:
            duration = 600  # ê¸°ë³¸ê°’ 10ë¶„
        
        # ëª©í‘œ ë¹„íŠ¸ë ˆì´íŠ¸ ê³„ì‚° (kbps)
        target_bitrate = int((target_size_mb * 8 * 1024) / duration)
        target_bitrate = max(32, min(target_bitrate, 128))  # 32~128kbps
        
        subprocess.run([
            'ffmpeg', '-i', input_path,
            '-vn',  # ë¹„ë””ì˜¤ ì œê±°
            '-acodec', 'libmp3lame',
            '-b:a', f'{target_bitrate}k',
            '-ar', '16000',  # 16kHz ìƒ˜í”Œë ˆì´íŠ¸
            '-ac', '1',  # ëª¨ë…¸
            '-y',
            output_path
        ], capture_output=True, check=True)
        
        return True
    except Exception as e:
        print(f"âŒ ì••ì¶• ì‹¤íŒ¨: {e}")
        return False


def split_audio(input_path, chunk_duration=300):
    """ì˜¤ë””ì˜¤ë¥¼ ì²­í¬ë¡œ ë¶„í•  (5ë¶„ ë‹¨ìœ„)"""
    duration = get_audio_duration(input_path)
    num_chunks = math.ceil(duration / chunk_duration)
    
    chunks = []
    for i in range(num_chunks):
        start_time = i * chunk_duration
        chunk_path = f"{input_path}_chunk_{i}.mp3"
        
        subprocess.run([
            'ffmpeg', '-i', input_path,
            '-ss', str(start_time),
            '-t', str(chunk_duration),
            '-acodec', 'libmp3lame',
            '-b:a', '64k',
            '-ar', '16000',
            '-ac', '1',
            '-y',
            chunk_path
        ], capture_output=True)
        
        if os.path.exists(chunk_path):
            chunks.append(chunk_path)
    
    return chunks


def transcribe(audio_file):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    try:
        # 1. webmìœ¼ë¡œ ì„ì‹œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.webm') as temp_audio:
            audio_file.save(temp_audio.name)
            webm_path = temp_audio.name
        
        file_size = os.path.getsize(webm_path)
        print(f"ğŸ“ webm íŒŒì¼ í¬ê¸°: {file_size} bytes")
        
        if file_size < 1000:
            os.unlink(webm_path)
            print("âŒ íŒŒì¼ ë„ˆë¬´ ì‘ìŒ")
            return ""
        
        # 2. ffmpegë¡œ mp3 ë³€í™˜
        mp3_path = webm_path.replace('.webm', '.mp3')
        result = subprocess.run([
            'ffmpeg', '-i', webm_path,
            '-acodec', 'libmp3lame',
            '-b:a', '64k',
            '-ar', '16000',
            '-ac', '1',
            '-y',
            mp3_path
        ], capture_output=True, text=True)
        
        print(f"ğŸ“ ffmpeg ê²°ê³¼: {result.returncode}")
        if result.stderr:
            print(f"ğŸ“ ffmpeg stderr: {result.stderr[-200:]}")  # ë§ˆì§€ë§‰ 200ìë§Œ
        
        if result.returncode != 0 or not os.path.exists(mp3_path):
            if os.path.exists(webm_path):
                os.unlink(webm_path)
            print("âŒ ffmpeg ë³€í™˜ ì‹¤íŒ¨")
            return ""
        
        mp3_size = os.path.getsize(mp3_path)
        print(f"ğŸ“ mp3 íŒŒì¼ í¬ê¸°: {mp3_size} bytes")
        
        # 3. Whisper API í˜¸ì¶œ
        with open(mp3_path, "rb") as audio:
            response = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio,
                language="ko",
                response_format="text"
            )
        
        print(f"âœ… Whisper ì‘ë‹µ: '{response}'")
        
        # 4. ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for f in [webm_path, mp3_path]:
            if os.path.exists(f):
                os.unlink(f)
        
        return response
    
    except Exception as e:
        print(f"âŒ Whisper ì „ì‚¬ ì‹¤íŒ¨: {e}")
        return ""


def extract_and_transcribe(video_file):
    """ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ í›„ í…ìŠ¤íŠ¸ ë³€í™˜ (ëŒ€ìš©ëŸ‰ ì§€ì›)"""
    try:
        # ë¹„ë””ì˜¤ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_video:
            video_file.save(temp_video.name)
            temp_video_path = temp_video.name
        
        # ì˜¤ë””ì˜¤ ì¶”ì¶œ + ì••ì¶•
        audio_path = temp_video_path + '_audio.mp3'
        
        subprocess.run([
            'ffmpeg', '-i', temp_video_path,
            '-vn',
            '-acodec', 'libmp3lame',
            '-b:a', '64k',
            '-ar', '16000',
            '-ac', '1',
            '-y',
            audio_path
        ], capture_output=True, check=True)
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(audio_path)
        
        transcripts = []
        
        if file_size > MAX_SIZE_BYTES:
            # ì²­í¬ë¡œ ë¶„í• 
            chunks = split_audio(audio_path)
            for chunk_path in chunks:
                with open(chunk_path, "rb") as audio:
                    response = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio,
                        response_format="text"
                    )
                    transcripts.append(response)
                os.unlink(chunk_path)
        else:
            with open(audio_path, "rb") as audio:
                response = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio,
                    response_format="text"
                )
                transcripts.append(response)
        
        # ì •ë¦¬
        for f in [temp_video_path, audio_path]:
            if os.path.exists(f):
                os.unlink(f)
        
        return ' '.join(transcripts)
    
    except Exception as e:
        print(f"âŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise e


def transcribe_stream(audio_chunks):
    """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ (ì²­í¬ ë‹¨ìœ„)"""
    try:
        transcripts = []
        
        for chunk in audio_chunks:
            with tempfile.NamedTemporaryFile(delete=False, suffix='.webm') as temp:
                temp.write(chunk)
                temp_path = temp.name
            
            with open(temp_path, "rb") as audio:
                response = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio,
                    response_format="text"
                )
                transcripts.append(response)
            
            os.unlink(temp_path)
        
        return transcripts
    
    except Exception as e:
        print(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ ì‹¤íŒ¨: {e}")
        raise e
